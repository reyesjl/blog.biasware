---
layout: post
title: "Algorithmic Colonialism: AI and Global Digital Power Imbalances"
date: 2025-08-14
categories: [research, AI]
tags: [algorithmic-colonialism, global-inequality, AI-bias]
description: "Exploring how AI systems reinforce global power imbalances and what can be done to create a more inclusive AI future."
---

> Notice: This paper was human reviewed and human edited. Research and development was aided by AI tools for transcription, summarization, and drafting support. Feel free to counter any claims or findings. If something is incorrect, please provide feedback. Reach us at contact@biasware.com.

## Introduction

Artificial Intelligence is often hailed as a global revolution, but in reality its benefits and influence are unevenly distributed[[1]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=The%20development%20and%20deployment%20of,targeted%20strategies%20to%20address%20them). A growing chorus of critics warns that AI is reproducing old patterns of colonial inequality in a digital form. **Algorithmic colonialism** refers to the way AI systems and digital platforms reinforce the dominance of wealthy, predominantly Western nations by marginalizing the voices, data, and knowledge of less powerful regions. From the datasets that teach AI how to "think," to the platforms controlling information flow, the Global South finds itself largely on the sidelines. This report delves into how AI, intentionally or not, can mirror historical colonial dynamics ‚Äì and what can be done to create a more inclusive AI future.

## Defining Algorithmic Colonialism

At its core, algorithmic colonialism is the **digital-age continuation of historical power imbalances**. It describes a process where **dominant tech systems from wealthy (often formerly colonial) nations are imposed on less powerful communities**, leading to new forms of dependency and control[[2]](https://climate.sustainability-directory.com/term/algorithmic-colonialism/#:~:text=To%20provide%20a%20more%20nuanced,just%20passively%20reflecting%20existing%20inequalities). Just as empires once extracted resources and imposed their rule overseas, today‚Äôs tech giants extract data and deploy algorithms worldwide under the guise of innovation. The term builds on concepts like ‚Äúdigital colonialism‚Äù and ‚Äúdata colonialism,‚Äù which highlight how corporations treat personal data as a resource to be mined much like colonial powers seized land and gold[[3]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=The%20line%20between%20these%20forces,The%20Age%20of%20Surveillance%20Capitalism)[[4]](https://networkcultures.org/blog/2022/12/13/how-to-resist-against-data-colonialism-interview-with-nick-couldry-ulises-mejias/#:~:text=Nick%20Couldry%20and%20Ulises%20Mejias%3A,that%20involves%20collecting%2C%20processing%2C%20and).

This phenomenon was brought into focus by researchers in the late 2010s. For example, **Abeba Birhane**, an Ethiopian scholar, describes *‚Äúcolonialism in the age of AI‚Äù* as manifesting through *‚Äústate-of-the-art algorithms‚Äù* and **‚ÄúAI-driven solutions‚Äù that are unsuited to local problems**, ultimately leaving regions like Africa dependent on Western software and infrastructure[[5]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Algorithmic%20Colonisation%20of%20Africa). In other words, Silicon Valley‚Äôs technologies are not neutral exports; they often come with embedded Western values and assumptions. The **origins of the concept** trace to the realization that the AI boom was largely centered in North America, Europe, and East Asia, and that the rest of the world was becoming a passive consumer of algorithms built elsewhere. Scholars began drawing parallels between **data extraction and colonial extraction** ‚Äì Shoshana Zuboff famously observed that tech companies treat our personal behaviors and culture as ‚Äúraw material free for the taking,‚Äù much as colonial powers claimed lands and peoples[[3]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=The%20line%20between%20these%20forces,The%20Age%20of%20Surveillance%20Capitalism). Algorithmic colonialism thus frames modern AI as part of a continuum of domination, repackaged in digital form.

## AI Training Data Bias: Geographic and Cultural Imbalances

AI systems are only as good ‚Äì and as fair ‚Äì as the data they are trained on. Here lies a fundamental imbalance: the **vast majority of AI training data comes from wealthy, English-speaking regions**, while voices from the Global South are grossly underrepresented[[6]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=AI%20thrives%20on%20data,platform%20and%20similar%20news%20archives). The internet ‚Äì which provides the bulk of data for training large language models and other AI ‚Äì is dominated by content from the Global North. **English is by far the most common language online**, accounting for roughly 60% of content on the web, even though only about 16% of people speak it[[7]](https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102#:~:text=English%20is%20by%20far%20the,13%20billion%20speakers). By contrast, languages spoken by huge populations have a tiny online footprint (for example, Chinese speakers are 14% of the world, but Chinese appears in only ~1.4% of top websites[[7]](https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102#:~:text=English%20is%20by%20far%20the,13%20billion%20speakers)). **The graphic below** illustrates this stark disparity between languages spoken versus content available online, which directly feeds into AI datasets![][image1]

**English dominates the web, far out of proportion to its share of world population.** This means AI trained on internet data ‚Äúlearns‚Äù a worldview heavily skewed toward Western and Anglophone content. A recent analysis noted that *less than 1%* of the data used to train large AI models comes from **African or Southeast Asian languages**, even though billions speak them[[8]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=Consequences%3A). As a result, these models struggle with languages like Swahili, Hindi, Tamil or Lao, and often fail to grasp non-Western contexts[[9]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=,exist%20to%20an%20AI%20model)[[10]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=A%20recent%20News%20Feature%20in,of%20African%20languages%2C%20researchers%20led). Meanwhile, whole cultures and knowledge systems that aren‚Äôt digitized in Western-centric datasets are effectively invisible to AI. Non-Western ways of thinking, storytelling, and problem-solving are **underrepresented**, leading to what one writer calls *‚Äúcultural erasure‚Äù* ‚Äì if something isn‚Äôt in English or on Wikipedia, *it might as well not exist to an AI model*[[11]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=%2A%20Cultural%20erasure%3A%20Non,exist%20to%20an%20AI%20model).

## How Bias Manifests in AI Systems

These training data disparities aren‚Äôt just abstract statistics ‚Äì they have **real-world effects on AI behavior**. When AI systems trained on one part of the world are applied globally, they often misfire or discriminate. Below are a few prominent examples of how **algorithmic bias** tied to data imbalance shows up in AI applications:

* **üí¨ Biased Language Models:** Large language models (like chatbots and translation tools) perform impressively in English, but **flounder in many non-Western languages**. They may produce awkward or inaccurate translations, struggle with local idioms, or default to Western examples. For instance, an editorial in *Nature* notes that GPT-style models *‚Äútrained mainly on English and Western culture-centric data‚Äù* perform poorly in languages like Hindi or Xhosa and miss cultural nuances entirely. This means users in those language communities get inferior AI services ‚Äì an English query might yield a detailed answer, while a Swahili query gets confusion or silence. Such models can also inadvertently **amplify Western perspectives** as ‚Äúuniversal,‚Äù overlooking context from the Global South in everything from medical advice to historical information.

* **ü§ñ Facial Recognition & Imagery:** AI vision systems have shown striking biases when confronted with faces or scenes outside the datasets they were taught on. A famous study by Joy Buolamwini found that commercial face recognition systems, trained mostly on images of light-skinned Westerners, had error rates of **over 34% when identifying darker-skinned women**, versus near 0% for white men. In other words, the AI could *hardly recognize* many Black women as human faces. This bias isn‚Äôt just about identity ‚Äì it‚Äôs about safety and rights. Such flawed systems have led to false arrests when police tech misidentifies people of color. Likewise, image recognition AI might label non-Western cultural attire or environments incorrectly (for example, seeing an Indigenous dress as a ‚Äúcostume‚Äù or a rural farming scene as ‚Äúwilderness‚Äù) because the model was never taught about those contexts. The problem stems from **Eurocentric training images**, resulting in AI that literally doesn‚Äôt see people from certain backgrounds clearly.

* **üåê Content Moderation Failures:** Social media and content platforms use AI filters to detect hate speech, misinformation, or violence ‚Äì but these filters work unevenly across languages. **Algorithms attuned to English** may completely miss dangerous content written in, say, Amharic or Burmese. A tragic case occurred in Myanmar, where Facebook‚Äôs lack of Burmese-language moderation enabled hate speech calling for violence against the Rohingya minority to spread unchecked. Researchers and even the U.N. found that Facebook‚Äôs AI (and human) moderation was essentially blind to local language incitement, **contributing to a genocide** in 2017. This exemplifies how a one-size-fits-all algorithm, designed in California, failed a community due to linguistic and cultural ignorance. Beyond extreme cases like Myanmar, everyday content moderation tends to reflect the cultural norms of Silicon Valley ‚Äì often **flagging posts by users in the Global South as ‚Äúoffensive‚Äù or ‚Äúmisinformation‚Äù mistakenly** because the AI lacks local context to interpret slang, satire, or political discourse. The result is either harmful content slipping through in under-served regions, or harmless content being censored, both of which silence marginalized voices.

These examples underscore a pattern: **when AI‚Äôs knowledge is lopsided, its mistakes are lopsided too.** The technology ends up serving some groups better than others, which in turn deepens digital inequality.

## Voices from the Global South

Critiques of algorithmic colonialism are not just coming from Western academia; **scholars and activists from marginalized regions are leading the call for change**. Their perspectives highlight lived experiences of AI‚Äôs imbalance and propose visions for a more inclusive tech future:

* **African Perspectives:** African researchers have been outspoken about how AI solutions from Silicon Valley often ignore local realities. Abeba Birhane describes how Western tech firms roll out ‚ÄúAI-driven solutions‚Äù in Africa ‚Äì like population mapping or fintech apps ‚Äì that don‚Äôt actually solve African problems and instead foster **dependency on foreign systems**. As she notes, much of Africa‚Äôs digital infrastructure (from social media to ride-sharing) is controlled by Western monopolies, who frame their services as ‚Äúconnecting‚Äù or ‚Äúsaving‚Äù Africa while extracting data and profits. This dynamic echoes the colonial mentality of ‚Äúwe know what‚Äôs best for you.‚Äù Other African voices, such as members of the **Deep Learning Indaba** (a pan-African AI community) and **Masakhane** (an open-source African language AI project), stress the importance of *AI by Africans, for Africans*. They argue that **local context and languages must be central**: for example, Masakhane‚Äôs researchers are creating translation models for dozens of African languages and benchmarks to test AI performance on African context tasks.

* **Indigenous and Under-represented Communities:** Indigenous scholars warn that AI can perpetrate *‚Äúepistemological violence‚Äù* ‚Äì a stripping away or misrepresentation of their ways of knowing. **Indigenous data** (traditional knowledge, cultural expressions, even genetic or geographic data) is at risk of being appropriated by algorithms without consent or understanding. A study in Cameroon introduced the concept of *algorithmic colonialism* in the context of Indigenous data sovereignty, showing how tech projects were mining local knowledge (for instance, using images of sacred artifacts or recordings of tribal songs in training data) and **commodifying it without regard for its cultural significance**. The authors documented how Western-designed systems, from health apps to mapping tools, often *fail to accommodate Indigenous worldviews* ‚Äì effectively forcing communities to fit into Western data categories or be ignored. In response, Indigenous activists and researchers are advocating for **‚Äúdecolonial AI‚Äù frameworks** that put their communities in control of their data and AI use. This includes demanding **ethical data collection** (with informed consent and respect for cultural context) and developing AI that serves community-defined goals rather than corporate profit. The message from marginalized communities is clear: *‚ÄúNothing about us without us‚Äù* ‚Äì AI should not be another way outsiders speak *for* them or about them, but a tool they have a say in shaping.

## Risks and Consequences of the Imbalance

Why does it matter if AI systems are skewed toward one part of the world‚Äôs data and values? The stakes are high: **unchecked algorithmic colonialism threatens to widen global inequalities and erode cultural diversity**. Some key risks and consequences include:

* **Policy Blind Spots:** As governments and organizations increasingly rely on AI for decision-making (from welfare distribution to policing and healthcare), algorithms trained on foreign or biased data can lead to harmful *blind spots*. For example, a predictive policing AI developed in a Western city might misidentify crime patterns in an African or Latin American city because it doesn‚Äôt understand local social dynamics ‚Äì possibly leading to wrongful targeting of certain neighborhoods. In public health, AI models might overlook diseases or risk factors prevalent in tropical regions if the training data was mostly European. These blind spots mean that **policies guided by AI could ignore or misjudge the needs of the Global South**, reinforcing misallocation of resources or ineffective interventions. It‚Äôs a new form of *‚Äúone-size-fits-all‚Äù* policy approach, reminiscent of colonial-era policies that failed to account for local contexts.

* **Digital Dependency and Monopolies:** When only a handful of countries (and companies) design the world‚Äôs AI, everyone else becomes **dependent on foreign technology**. This dependency can stifle local innovation ‚Äì why develop a local solution if a Silicon Valley product is imposed as the standard? As Birhane noted, Africa‚Äôs tech ecosystem can become reliant on Western infrastructure, leaving little room for homegrown alternatives. Moreover, the concentration of AI power in a few big tech firms creates a monopoly-like scenario on a global scale. Countries without their own AI capabilities may have to accept the terms and worldview embedded in imported systems. This **digital dependence** is risky: it can lead to **economic and security vulnerabilities** (imagine if critical sectors like finance or energy rely on black-box AI from abroad), and it perpetuates a colonial dynamic of *‚Äúproducer vs consumer‚Äù* states in technology.

* **Cultural Erasure and Language Extinction:** As AI and digital content shape what knowledge is accessible, there‚Äôs a real fear of **cultural erosion**. When younger generations grow up with AI assistants, search engines, and media feeds that recognize only dominant languages and narratives, marginalized cultures may be further pushed aside. UNESCO estimates that many minority languages are at risk of extinction this century ‚Äì and the digital realm is both a battleground and a lifeline for them. If AI only ‚Äúspeaks‚Äù English (or a few major tongues), speakers of Indigenous or lesser-known languages might shift to those languages online, accelerating the loss of their mother tongues. Additionally, AI-generated content could flood the internet with Western-centric stories and imagery, **drowning out local content**. This results in a subtle form of cultural imperialism: the homogenization of knowledge. As one analysis put it, *‚Äúin a digital-first world limited to English content, there is a real risk of cultural erasure, with younger generations growing up less aware of local history and culture.‚Äù* In short, algorithmic bias doesn‚Äôt just harm accuracy ‚Äì it can chip away at the rich tapestry of human languages and traditions.

* **Reinforcing Global Inequality:** Perhaps the broadest consequence is that AI could **entrench the divide between the tech-rich and tech-poor regions**. If current trends continue, AI will augment productivity and growth in the countries that lead in AI, while others lag further behind. Wealthy nations will develop AI policies and standards to their advantage, potentially exporting them to less powerful ones. This could mirror the colonial economy of old: a flow of data and AI services replaces the flow of raw materials, but the power imbalance remains. The *Global South could become merely a data source and market for AI*, rather than an equal innovator. The voices and problems that AI addresses would skew toward those of the Global North. Such **inequitable development** risks deepening socioeconomic gaps ‚Äì from who reaps AI‚Äôs economic rewards to who bears its surveillance and labor downsides. As a sobering warning, experts note we risk a future where *‚Äúglobal power [is] further concentrated in a handful of companies and countries‚Äù* and **AI systems ‚Äúcan‚Äôt understand or serve most of the world‚Äôs population.‚Äù**

In summary, algorithmic colonialism is not just about representation in datasets ‚Äì it translates into **real consequences for knowledge, governance, and self-determination** in the digital age. The imbalance, if unaddressed, could solidify a two-tier world: one where AI works primarily for the historically privileged, while others are left with its flaws and without a voice in its direction.

## Towards Inclusive AI: Pathways and Solutions

While the challenges are immense, they are not insurmountable. A growing movement of researchers, policymakers, and communities around the world is seeking to **‚Äúdecolonize‚Äù AI and make it more inclusive**. Here we outline several strategies and frameworks that can help rebalance global AI development and ensure that diverse voices and knowledge systems are respected:

* **Global South-Led Initiatives:** Supporting and amplifying AI research, development, and policy initiatives from the Global South is crucial. This includes funding local AI startups, supporting African and Asian tech hubs, and prioritizing **South-South cooperation** in technology. For instance, the **African Union‚Äôs Agenda 2063** emphasizes the importance of African solutions to African problems, including in the tech domain. Initiatives like the **Deep Learning Indaba** and **Masakhane** are prime examples of African-led efforts to shape AI that respects local languages and contexts.

* **Inclusive Data Practices:** To combat data bias, it‚Äôs essential to develop **inclusive data practices** that ensure diverse representation in AI training datasets. This can be achieved by **crowdsourcing data from a global pool** of contributors, emphasizing underrepresented languages and contexts. Collaborative initiatives like **Common Voice** (for voice recognition data) and **Wikipedia‚Äôs language diversity efforts** are steps in the right direction. Moreover, involving local communities in data collection and curation can help ensure that their knowledge and perspectives are accurately represented.

* **Decolonizing AI Education:** Revamping AI education to include perspectives and contributions from the Global South is vital. This means not only translating educational materials into more languages but also incorporating **non-Western examples, case studies, and ethical frameworks** into AI curricula. Partnerships between universities in the Global North and South can facilitate knowledge exchange and co-creation of educational content. Programs like the **AI4D Africa** initiative aim to strengthen African universities‚Äô capacity to teach and research AI.

* **Ethical and Responsible AI Frameworks:** Developing and adhering to ethical AI frameworks that prioritize human rights, dignity, and cultural sensitivity is essential. This includes ensuring transparency in AI systems, obtaining informed consent for data use, and allowing individuals to opt-out of AI surveillance systems. The **UN‚Äôs Guiding Principles on Business and Human Rights** provide a useful framework for holding tech companies accountable for the societal impacts of their AI systems. Moreover, involving ethicists, sociologists, and representatives from affected communities in AI system design and deployment can help identify and mitigate potential harms.

* **Advocacy and Awareness:** Raising awareness about algorithmic colonialism and advocating for policy changes at national and international levels is crucial. This includes pushing for **regulations that promote data sovereignty, protect against discriminatory AI practices, and ensure accountability for AI harms**. Grassroots movements, supported by global allies, can pressure governments and corporations to prioritize inclusive and equitable AI development. Reports like this one play a key role in shedding light on these issues and mobilizing action.

In conclusion, addressing algorithmic colonialism requires a concerted and inclusive effort from all stakeholders ‚Äì including governments, tech companies, civil society, and the global research community. By working together, it is possible to reshape the AI landscape into one that truly reflects and serves the diverse tapestry of human societies and cultures.

**Sources:**

1. Abeba Birhane (2020). *‚ÄúAlgorithmic Colonisation of Africa.‚Äù* **The Elephant** ‚Äì Analysis piece on how Western AI solutions impose on Africa[\[42\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Traditional%20colonial%20power%20seeks%20unilateral,of%20digital%20ecosystems%20and%20infrastructure)[\[19\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=outside%20the%20market%20sphere%20and,population%20knowledge%20of%20the%20continent).

2. Alliance for AI & Humanity (2025). *‚ÄúAI ‚Äî West vs the Rest: Bridging the Global Divide in Artificial Intelligence.‚Äù* **Medium** ‚Äì Discusses global AI inequality and data colonialism, with stats on language data \<1% for African/SE Asian languages[\[6\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=AI%20thrives%20on%20data,platform%20and%20similar%20news%20archives)[\[9\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=,exist%20to%20an%20AI%20model) and solutions like open data and local AI hubs[\[32\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=resourced%20regions%20to%20fine,lower%20the%20barrier%20to%20entry)[\[34\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=We%20need%20public%20investment%20to,libraries%20in%20the%20past%20century).

3. Nature Machine Intelligence Editorial (May 2025). *‚ÄúLocalizing AI in the global south.‚Äù* ‚Äì Notes that major LLMs trained on Western data perform poorly in non-Western languages[\[13\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=Much%20attention%20is%20directed%20at,Western%20contexts%20and%20languages)[\[10\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=A%20recent%20News%20Feature%20in,of%20African%20languages%2C%20researchers%20led) and emphasizes risk of cultural erasure if AI remains English-centric[\[30\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=Better%20data%20representation%20for%20native,can%20serve%20localized%20societal%20needs).

4. Nouridin Melo (2025). *‚ÄúAlgorithmic Colonialism and the Appropriation of Indigenous Data: Safeguarding Cultural Epistemologies in the Digital Age.‚Äù* **Preprint** ‚Äì Introduces the concept in a Cameroonian context, defining algorithmic colonialism as extraction of Indigenous data that reinforces Western dominance[\[28\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=governing%20data%20collection%20and%20use,increasingly%20vulnerable%20to%20algorithmic%20appropriation) and calling for Indigenous data sovereignty frameworks[\[23\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=qualitative%20interviews%20with%20Indigenous%20knowledge,to%20broader%20discussions%20on%20digital).

5. Joy Buolamwini et al. (2018). *‚ÄúGender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.‚Äù* ‚Äì Research finding facial recognition systems much less accurate for dark-skinned women, as reported by MIT News[\[14\]](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212#:~:text=For%20darker,been%20guessing%20gender%20at%20random), highlighting bias from unbalanced training images.

6. Daniel Zaleznik (2022). *‚ÄúFacebook and Genocide: How Facebook contributed to genocide in Myanmar‚Ä¶‚Äù* **Systemic Justice Journal (Harvard)** ‚Äì Details Facebook‚Äôs role in Myanmar‚Äôs violence due to lack of Burmese content moderation[\[15\]](https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/#:~:text=dominated%20online%20spaces%2C%20with%20early,especially%20during%20the%202017%20genocide), exemplifying algorithmic blind spots with non-English content.

7. Voronoi/Visual Capitalist (2023). *‚ÄúMost Commonly Used Languages on the Internet.‚Äù* ‚Äì Data visualization showing English at \~60% of web content vs. tiny shares for languages of the Global South[\[7\]](https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102#:~:text=English%20is%20by%20far%20the,13%20billion%20speakers)![][image1]  
   , illustrating the imbalance in digital data that feeds AI.

---

[\[1\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=The%20development%20and%20deployment%20of,targeted%20strategies%20to%20address%20them) [\[6\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=AI%20thrives%20on%20data,platform%20and%20similar%20news%20archives) [\[8\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=Consequences%3A) [\[9\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=,exist%20to%20an%20AI%20model) [\[11\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=%2A%20Cultural%20erasure%3A%20Non,exist%20to%20an%20AI%20model) [\[12\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=The%20irony%20is%20striking%3A%20Global,of%20this%20data%20accrue%20elsewhere) [\[31\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=We%20risk%3A) [\[32\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=resourced%20regions%20to%20fine,lower%20the%20barrier%20to%20entry) [\[33\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=Example%3A) [\[34\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=We%20need%20public%20investment%20to,libraries%20in%20the%20past%20century) [\[35\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=enough) [\[36\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=,like%20%2010%20Hugging%20Face%E2%80%99s) [\[37\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=4,Data%20Colonialism) [\[38\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=5,Startups%20and%20Innovation) [\[39\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=%E2%97%8F%20A%20researcher%20in%20Nairobi,systems%20and%20build%20their%20own) [\[40\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=The%20dream%20is%20to%20build,a%20world%20where) [\[41\]](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea#:~:text=,handful%20of%20companies%20and%20countries) AI ‚Äî West vs the Rest: Bridging the Global Divide in Artificial Intelligence | by Alliance for AI & Humanity | Medium

[https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea](https://medium.com/@aaih/ai-west-vs-the-rest-bridging-the-global-divide-in-artificial-intelligence-00e6e04450ea)

[\[2\]](https://climate.sustainability-directory.com/term/algorithmic-colonialism/#:~:text=To%20provide%20a%20more%20nuanced,just%20passively%20reflecting%20existing%20inequalities) Algorithmic Colonialism ‚Üí Term

[https://climate.sustainability-directory.com/term/algorithmic-colonialism/](https://climate.sustainability-directory.com/term/algorithmic-colonialism/)

[\[3\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=The%20line%20between%20these%20forces,The%20Age%20of%20Surveillance%20Capitalism) [\[5\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Algorithmic%20Colonisation%20of%20Africa) [\[19\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=outside%20the%20market%20sphere%20and,population%20knowledge%20of%20the%20continent) [\[20\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Currently%2C%20much%20of%20Africa%E2%80%99s%20digital,Especially%20when%20you%20consider) [\[29\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Colonialism%20in%20the%20age%20of,on%20Western%20software%20and%20infrastructure) [\[42\]](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/#:~:text=Traditional%20colonial%20power%20seeks%20unilateral,of%20digital%20ecosystems%20and%20infrastructure) Algorithmic Colonisation of Africa \- The Elephant

[https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/](https://www.theelephant.info/analysis/2020/08/21/algorithmic-colonisation-of-africa/)

[\[4\]](https://networkcultures.org/blog/2022/12/13/how-to-resist-against-data-colonialism-interview-with-nick-couldry-ulises-mejias/#:~:text=Nick%20Couldry%20and%20Ulises%20Mejias%3A,that%20involves%20collecting%2C%20processing%2C%20and) Institute of Network Cultures | How to Resist Data Colonialism? Interview with Nick Couldry & Ulises Mejias

[https://networkcultures.org/blog/2022/12/13/how-to-resist-against-data-colonialism-interview-with-nick-couldry-ulises-mejias/](https://networkcultures.org/blog/2022/12/13/how-to-resist-against-data-colonialism-interview-with-nick-couldry-ulises-mejias/)

[\[7\]](https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102#:~:text=English%20is%20by%20far%20the,13%20billion%20speakers) Visualizing the Most Used Languages on the Internet \- Voronoi

[https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102](https://www.voronoiapp.com/other/Visualizing-the-Most-Used-Languages-on-the-Internet-102)

[\[10\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=A%20recent%20News%20Feature%20in,of%20African%20languages%2C%20researchers%20led) [\[13\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=Much%20attention%20is%20directed%20at,Western%20contexts%20and%20languages) [\[21\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=performances%20in%20other%20languages%20leads,specifically%20on%20African%20languages%2019) [\[22\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=Several%20grassroots%20initiatives%20are%20working,force%20behind%20the%20AfroBench%20initiative) [\[30\]](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46#:~:text=Better%20data%20representation%20for%20native,can%20serve%20localized%20societal%20needs) Localizing AI in the global south | Nature Machine Intelligence

[https://www.nature.com/articles/s42256-025-01057-z?error=cookies\_not\_supported\&code=0253e641-d062-417b-8939-8b1dc8b8ec46](https://www.nature.com/articles/s42256-025-01057-z?error=cookies_not_supported&code=0253e641-d062-417b-8939-8b1dc8b8ec46)

[\[14\]](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212#:~:text=For%20darker,been%20guessing%20gender%20at%20random) Study finds gender and skin-type bias in commercial artificial-intelligence systems | MIT News | Massachusetts Institute of Technology

[https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212)

[\[15\]](https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/#:~:text=dominated%20online%20spaces%2C%20with%20early,especially%20during%20the%202017%20genocide) [\[16\]](https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/#:~:text=Abstract%3A%20Facebook%20contributed%20to%20a,Rohingya%20Muslims%20in%20Northern%20Myanmar) [\[17\]](https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/#:~:text=feeds%20quickly%20became%20populated%20with,especially%20during%20the%202017%20genocide) Facebook and Genocide: How Facebook contributed to genocide in Myanmar and why it will not be held accountable \- Harvard Law School | Systemic Justice Project

[https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/](https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/)

[\[18\]](https://cis.cornell.edu/one-size-fits-all-content-moderation-fails-global-south#:~:text=One,in%20their%20culture%20and) One-size-fits-all content moderation fails the Global South

[https://cis.cornell.edu/one-size-fits-all-content-moderation-fails-global-south](https://cis.cornell.edu/one-size-fits-all-content-moderation-fails-global-south)

[\[23\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=qualitative%20interviews%20with%20Indigenous%20knowledge,to%20broader%20discussions%20on%20digital) [\[24\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=governing%20data%20collection%20and%20use,increasingly%20vulnerable%20to%20algorithmic%20appropriation) [\[25\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=,accommodate%20Cameroonian%20ways%20of%20knowing) [\[26\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=,communities%20across%20Cameroon%27s%20diverse%20regions) [\[27\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=enacted%20through%20algorithmic%20systems%20that,development%20within%20the%20Cameroonian%20context) [\[28\]](https://www.preprints.org/manuscript/202505.1403/v1#:~:text=governing%20data%20collection%20and%20use,increasingly%20vulnerable%20to%20algorithmic%20appropriation) Algorithmic Colonialism and the Appropriation of Indigenous Data: Safeguarding Cultural Epistemologies in the Digital Age\[v1\] | Preprints.org

[https://www.preprints.org/manuscript/202505.1403/v1](https://www.preprints.org/manuscript/202505.1403/v1)
